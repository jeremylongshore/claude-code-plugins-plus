{
  "id": "11-data-pipelines",
  "name": "Data Pipelines",
  "description": "Data pipeline skills covering ETL, data transformation, workflow orchestration, and streaming data processing.",
  "priority": "medium",
  "skills_count": 25,
  "estimated_generation_time": "7 minutes",
  "tags": ["etl", "airflow", "spark", "streaming", "data-engineering"],
  "target_audience": ["data engineers", "analytics engineers", "backend developers"],
  "skills": [
    "airflow-dag-generator",
    "airflow-operator-creator",
    "prefect-flow-builder",
    "dagster-pipeline-creator",
    "luigi-task-generator",
    "spark-job-creator",
    "pyspark-transformer",
    "spark-sql-optimizer",
    "kafka-stream-processor",
    "flink-job-creator",
    "beam-pipeline-builder",
    "dbt-model-generator",
    "dbt-test-creator",
    "sql-transform-helper",
    "data-quality-checker",
    "schema-validator",
    "data-lineage-tracker",
    "incremental-load-setup",
    "cdc-pipeline-creator",
    "data-partitioner",
    "file-format-converter",
    "compression-optimizer",
    "data-catalog-updater",
    "metadata-extractor",
    "pipeline-monitoring-setup"
  ]
}
