---
import PlaybookTemplate from '../../components/PlaybookTemplate.astro';

const meta = {
  title: "Self-Hosted Stack Setup",
  description: "Full infrastructure deployment with Docker/Kubernetes. Ollama, PostgreSQL, Redis, Prometheus, Grafana, Nginx - complete production stack with monitoring and backups.",
  category: "Infrastructure",
  wordCount: 5500,
  slug: "06-self-hosted-stack"
};
---

<PlaybookTemplate {...meta}>
  <div set:html={`<p><strong>Production Playbook for Infrastructure Engineers and DevOps</strong></p>

<p>Building a complete self-hosted AI infrastructure for Claude Code plugins eliminates cloud dependencies, ensures data privacy, and provides full control. This playbook provides production-ready Docker Compose configurations, Kubernetes deployments, monitoring with Prometheus/Grafana, automated backups, and disaster recovery procedures.</p>

<h2>Architecture Overview</h2>

<h3>Self-Hosted Stack Components</h3>

<pre><code class="language-mermaid">graph TB
    A[Claude Code CLI] --&gt; B[Analytics Daemon]
    A --&gt; C[Ollama LLM Server]
    A --&gt; D[PostgreSQL Database]
    A --&gt; E[Redis Cache]

B --&gt; F[Prometheus Metrics]
C --&gt; F

F --&gt; G[Grafana Dashboard]

D --&gt; H[Backup Service]
E --&gt; H

I[Nginx Reverse Proxy] --&gt; B
I --&gt; C

J[Let&#039;s Encrypt] --&gt; I</code></pre>

<h3>Infrastructure Tiers</h3>

<table>
<thead>
<tr>
<th>Component</th>
<th>Purpose</th>
<th>Port</th>
<th>Storage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ollama</strong></td>
<td>Local LLM inference</td>
<td>11434</td>
<td>100GB (models)</td>
</tr>
<tr>
<td><strong>Analytics Daemon</strong></td>
<td>Real-time monitoring</td>
<td>3333, 3456</td>
<td>10GB (logs)</td>
</tr>
<tr>
<td><strong>PostgreSQL</strong></td>
<td>Persistent data</td>
<td>5432</td>
<td>50GB (database)</td>
</tr>
<tr>
<td><strong>Redis</strong></td>
<td>Caching, sessions</td>
<td>6379</td>
<td>5GB (cache)</td>
</tr>
<tr>
<td><strong>Prometheus</strong></td>
<td>Metrics collection</td>
<td>9090</td>
<td>20GB (metrics)</td>
</tr>
<tr>
<td><strong>Grafana</strong></td>
<td>Dashboards</td>
<td>3000</td>
<td>5GB (config)</td>
</tr>
<tr>
<td><strong>Nginx</strong></td>
<td>Reverse proxy, SSL</td>
<td>80, 443</td>
<td>1GB (logs)</td>
</tr>
</tbody>
</table>

<p><strong>Total Storage</strong>: ~191GB minimum</p>

<hr>

<h2>Docker Compose Setup</h2>

<h3>Complete Stack (docker-compose.yml)</h3>

<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3.8&#039;

services:
# Ollama LLM Server
ollama:
image: ollama/ollama:latest
container_name: ollama
ports:
- &quot;11434:11434&quot;
volumes:
- ollama_models:/root/.ollama
deploy:
resources:
reservations:
devices:
- driver: nvidia
count: 1
capabilities: [gpu]
restart: unless-stopped
healthcheck:
test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:11434/api/tags&quot;]
interval: 30s
timeout: 10s
retries: 3

# Analytics Daemon
analytics:
build: ./packages/analytics-daemon
container_name: analytics-daemon
ports:
- &quot;3333:3333&quot;  # HTTP API
- &quot;3456:3456&quot;  # WebSocket
volumes:
- analytics_data:/data
- &#36;{HOME}/.claude:/root/.claude:ro
environment:
- NODE_ENV=production
- PORT=3333
- WS_PORT=3456
restart: unless-stopped
healthcheck:
test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:3333/health&quot;]
interval: 30s
timeout: 5s
retries: 3

# PostgreSQL Database
postgres:
image: postgres:16-alpine
container_name: postgres
ports:
- &quot;5432:5432&quot;
volumes:
- postgres_data:/var/lib/postgresql/data
- ./backups/postgres:/backups
environment:
- POSTGRES_USER=claude
- POSTGRES_PASSWORD=&#36;{POSTGRES_PASSWORD}
- POSTGRES_DB=claude_prod
restart: unless-stopped
healthcheck:
test: [&quot;CMD-SHELL&quot;, &quot;pg_isready -U claude&quot;]
interval: 10s
timeout: 5s
retries: 5

# Redis Cache
redis:
image: redis:7-alpine
container_name: redis
ports:
- &quot;6379:6379&quot;
volumes:
- redis_data:/data
command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
restart: unless-stopped
healthcheck:
test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
interval: 10s
timeout: 3s
retries: 3

# Prometheus Metrics
prometheus:
image: prom/prometheus:latest
container_name: prometheus
ports:
- &quot;9090:9090&quot;
volumes:
- ./prometheus.yml:/etc/prometheus/prometheus.yml
- prometheus_data:/prometheus
command:
- &#039;--config.file=/etc/prometheus/prometheus.yml&#039;
- &#039;--storage.tsdb.path=/prometheus&#039;
- &#039;--storage.tsdb.retention.time=30d&#039;
restart: unless-stopped

# Grafana Dashboards
grafana:
image: grafana/grafana:latest
container_name: grafana
ports:
- &quot;3000:3000&quot;
volumes:
- grafana_data:/var/lib/grafana
- ./grafana/dashboards:/etc/grafana/provisioning/dashboards
- ./grafana/datasources:/etc/grafana/provisioning/datasources
environment:
- GF_SECURITY_ADMIN_PASSWORD=&#36;{GRAFANA_PASSWORD}
- GF_INSTALL_PLUGINS=redis-datasource
restart: unless-stopped
depends_on:
- prometheus

# Nginx Reverse Proxy
nginx:
image: nginx:alpine
container_name: nginx
ports:
- &quot;80:80&quot;
- &quot;443:443&quot;
volumes:
- ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
- ./nginx/ssl:/etc/nginx/ssl:ro
- nginx_logs:/var/log/nginx
restart: unless-stopped
depends_on:
- ollama
- analytics
- grafana

# Automated Backups
backup:
image: alpine:latest
container_name: backup-service
volumes:
- postgres_data:/source/postgres:ro
- redis_data:/source/redis:ro
- analytics_data:/source/analytics:ro
- ./backups:/backups
command: |
sh -c &#039;
apk add --no-cache postgresql-client redis
while true; do
DATE=&#36;(date +%Y-%m-%d_%H-%M-%S)

# Backup PostgreSQL
PGPASSWORD=&#36;&#36;POSTGRES_PASSWORD pg_dump -h postgres -U claude claude_prod &gt; /backups/postgres/backup_&#36;&#36;DATE.sql

# Backup Redis
redis-cli -h redis --rdb /backups/redis/dump_&#36;&#36;DATE.rdb

# Backup Analytics
tar -czf /backups/analytics/backup_&#36;&#36;DATE.tar.gz /source/analytics

# Delete old backups (keep 7 days)
find /backups -name &quot;backup_*.sql&quot; -mtime +7 -delete
find /backups -name &quot;dump_*.rdb&quot; -mtime +7 -delete
find /backups -name &quot;backup_*.tar.gz&quot; -mtime +7 -delete

echo &quot;Backup completed: &#36;&#36;DATE&quot;
sleep 86400  # Daily backups
done
&#039;
environment:
- POSTGRES_PASSWORD=&#36;{POSTGRES_PASSWORD}
restart: unless-stopped

volumes:
ollama_models:
analytics_data:
postgres_data:
redis_data:
prometheus_data:
grafana_data:
nginx_logs:

networks:
default:
name: claude_network</code></pre>

<h3>Environment Configuration (.env)</h3>

<pre><code class="language-bash"># .env
POSTGRES_PASSWORD=your-secure-password-here
GRAFANA_PASSWORD=your-grafana-password-here</code></pre>

<h3>Nginx Configuration</h3>

<pre><code class="language-nginx"># nginx/nginx.conf
events {
    worker_connections 1024;
}

http {
upstream ollama {
server ollama:11434;
}

upstream analytics {
server analytics:3333;
}

upstream grafana {
server grafana:3000;
}

# HTTP -&gt; HTTPS redirect
server {
listen 80;
server_name claude.example.com;
return 301 https://&#36;server_name&#36;request_uri;
}

# HTTPS
server {
listen 443 ssl http2;
server_name claude.example.com;

ssl_certificate /etc/nginx/ssl/fullchain.pem;
ssl_certificate_key /etc/nginx/ssl/privkey.pem;
ssl_protocols TLSv1.2 TLSv1.3;
ssl_ciphers HIGH:!aNULL:!MD5;

# Ollama API
location /api/ollama/ {
proxy_pass http://ollama/;
proxy_set_header Host &#36;host;
proxy_set_header X-Real-IP &#36;remote_addr;
}

# Analytics API
location /api/analytics/ {
proxy_pass http://analytics/api/;
proxy_set_header Host &#36;host;
proxy_set_header X-Real-IP &#36;remote_addr;
}

# Analytics WebSocket
location /ws/ {
proxy_pass http://analytics/;
proxy_http_version 1.1;
proxy_set_header Upgrade &#36;http_upgrade;
proxy_set_header Connection &quot;upgrade&quot;;
}

# Grafana
location / {
proxy_pass http://grafana/;
proxy_set_header Host &#36;host;
}
}
}</code></pre>

<h3>Deployment Commands</h3>

<pre><code class="language-bash"># Setup
mkdir -p backups/{postgres,redis,analytics}
mkdir -p grafana/{dashboards,datasources}
touch .env  # Add passwords

# Start stack
docker-compose up -d

# Download Ollama models
docker exec ollama ollama pull llama3.3:70b
docker exec ollama ollama pull qwen2.5-coder:32b

# Verify health
docker-compose ps
docker-compose logs -f

# Access services
# Ollama: http://localhost:11434
# Analytics: http://localhost:3333
# Grafana: http://localhost:3000
# Prometheus: http://localhost:9090</code></pre>

<hr>

<h2>Kubernetes Deployment</h2>

<h3>Complete Kubernetes Manifests</h3>

<p><strong>Namespace</strong>:</p>
<pre><code class="language-yaml"># namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: claude-stack</code></pre>

<p><strong>Ollama Deployment</strong>:</p>
<pre><code class="language-yaml"># ollama-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: claude-stack
spec:
  replicas: 3  # Scale with GPUs
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            memory: &quot;16Gi&quot;
            cpu: &quot;4&quot;
        volumeMounts:
        - name: models
          mountPath: /root/.ollama
        livenessProbe:
          httpGet:
            path: /api/tags
            port: 11434
          initialDelaySeconds: 60
          periodSeconds: 30
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: ollama-models-pvc
<hr>
apiVersion: v1
kind: Service
metadata:
name: ollama-service
namespace: claude-stack
spec:
selector:
app: ollama
ports:
- protocol: TCP
port: 11434
targetPort: 11434
type: ClusterIP
<hr>
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: ollama-models-pvc
namespace: claude-stack
spec:
accessModes:
- ReadWriteOnce
resources:
requests:
storage: 100Gi
storageClassName: fast-ssd</code></pre>

<p><strong>PostgreSQL StatefulSet</strong>:</p>
<pre><code class="language-yaml"># postgres-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: claude-stack
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:16-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_USER
          value: &quot;claude&quot;
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: POSTGRES_DB
          value: &quot;claude_prod&quot;
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: &quot;4Gi&quot;
            cpu: &quot;2&quot;
          limits:
            memory: &quot;8Gi&quot;
            cpu: &quot;4&quot;
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      resources:
        requests:
          storage: 50Gi
      storageClassName: fast-ssd
<hr>
apiVersion: v1
kind: Service
metadata:
name: postgres
namespace: claude-stack
spec:
selector:
app: postgres
ports:
- protocol: TCP
port: 5432
targetPort: 5432
clusterIP: None</code></pre>

<p><strong>Monitoring Stack</strong>:</p>
<pre><code class="language-yaml"># prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: claude-stack
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
        args:
          - &#039;--config.file=/etc/prometheus/prometheus.yml&#039;
          - &#039;--storage.tsdb.retention.time=30d&#039;
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: data
        persistentVolumeClaim:
          claimName: prometheus-data-pvc
<hr>
apiVersion: v1
kind: ConfigMap
metadata:
name: prometheus-config
namespace: claude-stack
data:
prometheus.yml: |
global:
scrape_interval: 15s
scrape_configs:
- job_name: &#039;ollama&#039;
static_configs:
- targets: [&#039;ollama-service:11434&#039;]
- job_name: &#039;postgres&#039;
static_configs:
- targets: [&#039;postgres:5432&#039;]
- job_name: &#039;analytics&#039;
static_configs:
- targets: [&#039;analytics-service:3333&#039;]</code></pre>

<h3>Deploy to Kubernetes</h3>

<pre><code class="language-bash"># Create namespace
kubectl apply -f namespace.yaml

# Create secrets
kubectl create secret generic postgres-secret \
--from-literal=password=&#039;your-secure-password&#039; \
-n claude-stack

# Deploy services
kubectl apply -f ollama-deployment.yaml
kubectl apply -f postgres-statefulset.yaml
kubectl apply -f prometheus-deployment.yaml

# Verify
kubectl get pods -n claude-stack
kubectl logs -f deployment/ollama -n claude-stack</code></pre>

<hr>

<h2>Monitoring with Prometheus & Grafana</h2>

<h3>Prometheus Configuration</h3>

<pre><code class="language-yaml"># prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
# Ollama metrics
- job_name: &#039;ollama&#039;
static_configs:
- targets: [&#039;ollama:11434&#039;]
metrics_path: &#039;/metrics&#039;

# Analytics daemon metrics
- job_name: &#039;analytics&#039;
static_configs:
- targets: [&#039;analytics:3333&#039;]
metrics_path: &#039;/metrics&#039;

# PostgreSQL metrics (using postgres_exporter)
- job_name: &#039;postgres&#039;
static_configs:
- targets: [&#039;postgres-exporter:9187&#039;]

# Redis metrics (using redis_exporter)
- job_name: &#039;redis&#039;
static_configs:
- targets: [&#039;redis-exporter:9121&#039;]

# Node metrics
- job_name: &#039;node&#039;
static_configs:
- targets: [&#039;localhost:9100&#039;]

alerting:
alertmanagers:
- static_configs:
- targets: [&#039;alertmanager:9093&#039;]

rule_files:
- &#039;/etc/prometheus/rules/*.yml&#039;</code></pre>

<h3>Alert Rules</h3>

<pre><code class="language-yaml"># prometheus/rules/alerts.yml
groups:
  - name: claude_stack_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: rate(llm_errors_total[5m]) &gt; 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;High LLM error rate&quot;
          description: &quot;Error rate is {{ &#36;value | humanizePercentage }}&quot;

# Ollama down
- alert: OllamaDown
expr: up{job=&quot;ollama&quot;} == 0
for: 1m
labels:
severity: critical
annotations:
summary: &quot;Ollama is down&quot;

# High memory usage
- alert: HighMemoryUsage
expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes &gt; 0.9
for: 5m
labels:
severity: warning
annotations:
summary: &quot;High memory usage&quot;
description: &quot;Memory usage is {{ &#36;value | humanizePercentage }}&quot;

# Database connection issues
- alert: PostgreSQLDown
expr: up{job=&quot;postgres&quot;} == 0
for: 1m
labels:
severity: critical
annotations:
summary: &quot;PostgreSQL is down&quot;</code></pre>

<h3>Grafana Dashboards</h3>

<p><strong>Claude Stack Dashboard (JSON)</strong>:</p>
<pre><code class="language-json">{
  &quot;dashboard&quot;: {
    &quot;title&quot;: &quot;Claude Code Self-Hosted Stack&quot;,
    &quot;panels&quot;: [
      {
        &quot;title&quot;: &quot;LLM Requests/sec&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;rate(llm_requests_total[5m])&quot;
          }
        ],
        &quot;type&quot;: &quot;graph&quot;
      },
      {
        &quot;title&quot;: &quot;Error Rate&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;rate(llm_errors_total[5m]) / rate(llm_requests_total[5m])&quot;
          }
        ],
        &quot;type&quot;: &quot;graph&quot;
      },
      {
        &quot;title&quot;: &quot;Response Latency (p95)&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;histogram_quantile(0.95, rate(llm_request_duration_seconds_bucket[5m]))&quot;
          }
        ],
        &quot;type&quot;: &quot;graph&quot;
      },
      {
        &quot;title&quot;: &quot;GPU Utilization&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;nvidia_gpu_duty_cycle&quot;
          }
        ],
        &quot;type&quot;: &quot;gauge&quot;
      },
      {
        &quot;title&quot;: &quot;Database Connections&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;pg_stat_database_numbackends&quot;
          }
        ],
        &quot;type&quot;: &quot;graph&quot;
      }
    ]
  }
}</code></pre>

<hr>

<h2>Backup Strategies</h2>

<h3>Automated Daily Backups</h3>

<pre><code class="language-bash">#!/bin/bash
# backup.sh - Automated backup script

DATE=&#36;(date +%Y-%m-%d_%H-%M-%S)
BACKUP_DIR=&quot;/backups&quot;

# PostgreSQL backup
echo &quot;Backing up PostgreSQL...&quot;
PGPASSWORD=&#36;POSTGRES_PASSWORD pg_dump -h localhost -U claude claude_prod | \
gzip &gt; &#36;BACKUP_DIR/postgres/backup_&#36;DATE.sql.gz

# Redis backup
echo &quot;Backing up Redis...&quot;
redis-cli --rdb &#36;BACKUP_DIR/redis/dump_&#36;DATE.rdb

# Analytics data
echo &quot;Backing up Analytics...&quot;
tar -czf &#36;BACKUP_DIR/analytics/backup_&#36;DATE.tar.gz /var/lib/analytics

# Ollama models (weekly only)
if [ &#36;(date +%u) -eq 1 ]; then
echo &quot;Backing up Ollama models (weekly)...&quot;
tar -czf &#36;BACKUP_DIR/ollama/models_&#36;DATE.tar.gz /root/.ollama
fi

# Upload to S3 (optional)
aws s3 sync &#36;BACKUP_DIR s3://my-backups/claude-stack/

# Delete old local backups (keep 7 days)
find &#36;BACKUP_DIR -name &quot;backup_*.sql.gz&quot; -mtime +7 -delete
find &#36;BACKUP_DIR -name &quot;dump_*.rdb&quot; -mtime +7 -delete
find &#36;BACKUP_DIR -name &quot;backup_*.tar.gz&quot; -mtime +7 -delete

echo &quot;Backup completed: &#36;DATE&quot;</code></pre>

<h3>Restore Procedures</h3>

<pre><code class="language-bash">#!/bin/bash
# restore.sh - Restore from backup

BACKUP_FILE=&#36;1

if [ -z &quot;&#36;BACKUP_FILE&quot; ]; then
echo &quot;Usage: ./restore.sh &lt;backup_file&gt;&quot;
exit 1
fi

# Stop services
docker-compose down

# Restore PostgreSQL
if [[ &#36;BACKUP_FILE == <em>&quot;postgres&quot;</em> ]]; then
gunzip -c &#36;BACKUP_FILE | \
PGPASSWORD=&#36;POSTGRES_PASSWORD psql -h localhost -U claude claude_prod
fi

# Restore Redis
if [[ &#36;BACKUP_FILE == <em>&quot;redis&quot;</em> ]]; then
cp &#36;BACKUP_FILE /var/lib/redis/dump.rdb
fi

# Restore Analytics
if [[ &#36;BACKUP_FILE == <em>&quot;analytics&quot;</em> ]]; then
tar -xzf &#36;BACKUP_FILE -C /
fi

# Restart services
docker-compose up -d

echo &quot;Restore completed from: &#36;BACKUP_FILE&quot;</code></pre>

<hr>

<h2>Security Hardening</h2>

<h3>Firewall Rules (UFW)</h3>

<pre><code class="language-bash"># Allow SSH
sudo ufw allow 22/tcp

# Allow HTTP/HTTPS (nginx only)
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp

# Block direct access to services
sudo ufw deny 11434/tcp  # Ollama
sudo ufw deny 3333/tcp   # Analytics
sudo ufw deny 5432/tcp   # PostgreSQL
sudo ufw deny 6379/tcp   # Redis

# Enable firewall
sudo ufw enable</code></pre>

<h3>SSL/TLS Certificates (Let's Encrypt)</h3>

<pre><code class="language-bash"># Install certbot
sudo apt-get install certbot

# Generate certificate
sudo certbot certonly --standalone -d claude.example.com

# Auto-renewal cron
echo &quot;0 0 <em> </em> * certbot renew --quiet&quot; | sudo crontab -</code></pre>

<h3>Database Security</h3>

<pre><code class="language-sql">-- PostgreSQL hardening

-- Create read-only user
CREATE USER claude_readonly WITH PASSWORD &#039;readonly-password&#039;;
GRANT CONNECT ON DATABASE claude_prod TO claude_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO claude_readonly;

-- Disable remote root access
ALTER USER postgres PASSWORD &#039;strong-random-password&#039;;
REVOKE ALL ON DATABASE postgres FROM PUBLIC;

-- Enable SSL
ALTER SYSTEM SET ssl = on;
ALTER SYSTEM SET ssl_cert_file = &#039;/etc/ssl/certs/server.crt&#039;;
ALTER SYSTEM SET ssl_key_file = &#039;/etc/ssl/private/server.key&#039;;</code></pre>

<hr>

<h2>Scaling & High Availability</h2>

<h3>Load Balancing Ollama</h3>

<pre><code class="language-yaml"># ollama-ha.yaml
apiVersion: v1
kind: Service
metadata:
  name: ollama-lb
  namespace: claude-stack
spec:
  selector:
    app: ollama
  ports:
  - protocol: TCP
    port: 11434
    targetPort: 11434
  type: LoadBalancer
  sessionAffinity: ClientIP  # Sticky sessions
<hr>
apiVersion: apps/v1
kind: Deployment
metadata:
name: ollama
namespace: claude-stack
spec:
replicas: 5  # 5 GPU nodes
strategy:
type: RollingUpdate
rollingUpdate:
maxSurge: 1
maxUnavailable: 1
template:
metadata:
labels:
app: ollama
spec:
containers:
- name: ollama
image: ollama/ollama:latest
resources:
limits:
nvidia.com/gpu: 1</code></pre>

<h3>PostgreSQL High Availability</h3>

<pre><code class="language-yaml"># postgres-ha.yaml (using Patroni)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-ha
  namespace: claude-stack
spec:
  serviceName: postgres-ha
  replicas: 3  # Primary + 2 replicas
  selector:
    matchLabels:
      app: postgres-ha
  template:
    metadata:
      labels:
        app: postgres-ha
    spec:
      containers:
      - name: postgres
        image: postgres:16-alpine
        env:
        - name: PATRONI_SCOPE
          value: &quot;postgres-cluster&quot;
        - name: PATRONI_REPLICATION_USERNAME
          value: &quot;replicator&quot;
        - name: PATRONI_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-ha-secret
              key: replication-password</code></pre>

<hr>

<h2>Best Practices</h2>

<h3>DO ✅</h3>

<ul>
<li><strong>Use persistent volumes</strong></li>
</ul>
   <pre><code class="language-yaml">volumes:
     - ollama_models:/root/.ollama  # Persistent
     - type: tmpfs                    # Temporary cache
       target: /tmp</code></pre>

<ul>
<li><strong>Implement health checks</strong></li>
</ul>
   <pre><code class="language-yaml">healthcheck:
     test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:11434/api/tags&quot;]
     interval: 30s
     timeout: 10s
     retries: 3
     start_period: 60s</code></pre>

<ul>
<li><strong>Use resource limits</strong></li>
</ul>
   <pre><code class="language-yaml">resources:
     limits:
       memory: &quot;16Gi&quot;
       cpu: &quot;4&quot;
       nvidia.com/gpu: 1
     requests:
       memory: &quot;8Gi&quot;
       cpu: &quot;2&quot;</code></pre>

<ul>
<li><strong>Automate backups</strong></li>
</ul>
   <pre><code class="language-bash"># Daily cron
   0 2 <em> </em> * /opt/backup.sh</code></pre>

<h3>DON'T ❌</h3>

<ul>
<li><strong>Don't expose services publicly</strong></li>
</ul>
   <pre><code class="language-yaml"># ❌ Direct internet exposure
   ports:
     - &quot;5432:5432&quot;  # PostgreSQL exposed!

# ✅ Use reverse proxy
# Access via Nginx only</code></pre>

<ul>
<li><strong>Don't skip SSL/TLS</strong></li>
</ul>
   <pre><code class="language-nginx"># ❌ HTTP only
   listen 80;

# ✅ HTTPS with redirect
listen 443 ssl http2;</code></pre>

<ul>
<li><strong>Don't use default passwords</strong></li>
</ul>
   <pre><code class="language-bash"># ❌ Weak password
   POSTGRES_PASSWORD=password

# ✅ Strong random password
POSTGRES_PASSWORD=&#36;(openssl rand -base64 32)</code></pre>

<hr>

<h2>Tools & Resources</h2>

<h3>Infrastructure as Code</h3>

<p><strong>Terraform</strong> (provision cloud resources):</p>
<pre><code class="language-hcl"># main.tf
resource &quot;aws_instance&quot; &quot;ollama_server&quot; {
  ami           = &quot;ami-0c55b159cbfafe1f0&quot;
  instance_type = &quot;g4dn.xlarge&quot;  # GPU instance

tags = {
Name = &quot;ollama-production&quot;
}
}</code></pre>

<p><strong>Ansible</strong> (configure servers):</p>
<pre><code class="language-yaml"># playbook.yml
<ul>
<li>hosts: ollama_servers</li>
</ul>
tasks:
- name: Install Docker
apt:
name: docker.io
state: present

- name: Deploy stack
community.docker.docker_compose:
project_src: /opt/claude-stack
state: present</code></pre>

<h3>Monitoring Tools</h3>

<ul>
<li><strong>Prometheus</strong>: Metrics collection</li>
<li><strong>Grafana</strong>: Dashboards</li>
<li><strong>AlertManager</strong>: Alert routing</li>
<li><strong>Loki</strong>: Log aggregation</li>
<li><strong>Jaeger</strong>: Distributed tracing</li>
</ul>

<hr>

<h2>Summary</h2>

<p><strong>Key Takeaways</strong>:</p>

<ul>
<li><strong>Docker Compose for dev/small deployments</strong> - Simple, fast setup</li>
<li><strong>Kubernetes for production/scale</strong> - High availability, auto-scaling</li>
<li><strong>Monitor everything</strong> - Prometheus + Grafana provide visibility</li>
<li><strong>Automate backups</strong> - Daily PostgreSQL, weekly models</li>
<li><strong>Harden security</strong> - Firewalls, SSL, strong passwords</li>
<li><strong>Scale horizontally</strong> - Multiple Ollama instances with load balancing</li>
<li><strong>Test disaster recovery</strong> - Practice restores monthly</li>
</ul>

<p><strong>Self-Hosted Stack Checklist</strong>:</p>
<ul>
<li>[ ] Deploy Ollama with GPU support</li>
<li>[ ] Set up PostgreSQL with backups</li>
<li>[ ] Configure Redis for caching</li>
<li>[ ] Deploy Analytics Daemon</li>
<li>[ ] Install Prometheus + Grafana</li>
<li>[ ] Configure Nginx reverse proxy</li>
<li>[ ] Enable SSL/TLS with Let's Encrypt</li>
<li>[ ] Set up automated backups (daily)</li>
<li>[ ] Configure firewall rules</li>
<li>[ ] Test disaster recovery</li>
<li>[ ] Document runbooks</li>
</ul>

<hr>

<p><strong>Last Updated</strong>: 2025-12-24</p>
<p><strong>Author</strong>: Jeremy Longshore</p>
<p><strong>Related Playbooks</strong>: <a href="./04-ollama-migration.md">Ollama Migration Guide</a>, <a href="./03-mcp-reliability.md">MCP Server Reliability</a></p>
`} />
</PlaybookTemplate>
